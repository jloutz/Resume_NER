{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flair_data_preparation.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJmUdwCDJQQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIZk8yz8KJsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/gdrive/My Drive/SAKI_2019/dataset\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTcnMHvrKM0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download flair library #\n",
        "! pip install flair"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h_89FPHKn7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import WIKINER_ENGLISH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCyfS290Kp7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. get the corpus\n",
        "wikiner_corpus: Corpus = WIKINER_ENGLISH().downsample(0.1)\n",
        "print(wikiner_corpus)\n",
        "# 3. make the tag dictionary from the corpus\n",
        "tag_dictionary = corpus.make_tag_dictionary(tag_type='ner')\n",
        "print(tag_dictionary.idx2item)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz5_TVavMYCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(wikiner_corpus.train[73])\n",
        "print(wikiner_corpus.train[73].to_tagged_string())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCS7O0RxRNUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.data_fetcher import NLPTaskDataFetcher\n",
        "\n",
        "downsample = 1.0 # 1.0 is full data, try a much smaller number like 0.01 to test run the code\n",
        "data_folder = '/content/gdrive/My Drive/SAKI_2019/dataset/flair' \n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# 1. get the corpus\n",
        "corpus: Corpus = NLPTaskDataFetcher.load_column_corpus(data_folder, columns,\n",
        "                                                             train_file='train_res_bilou_2.txt',\n",
        "                                                             test_file='test_res_bilou_2.txt',\n",
        "                                                           dev_file=None).downsample(downsample)\n",
        "print(corpus)\n",
        "\n",
        "# 3. make the tag dictionary from the corpus\n",
        "tag_dictionary = corpus.make_tag_dictionary(tag_type='ner')\n",
        "print(tag_dictionary.idx2item)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK4wyRrnjc6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for sent in corpus.test:\n",
        "  print(sent.to_tagged_string())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfgnZTHlmGcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent = corpus.test[0]\n",
        "for tok in sent.tokens:\n",
        "  print(tok.text)\n",
        "  for k in tok.tags:\n",
        "    print(\"   \"+k+\" \"+tok.tags[k].value)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}